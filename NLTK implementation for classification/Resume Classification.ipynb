{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation for Resume Classification using NLTK(Natural Language Toolkit) and TFIDF(Term Frequncy Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the particular packages required for implementation\n",
    "import os\n",
    "import sys\n",
    "from time import sleep\n",
    "\n",
    "#Data Wrangling and manipulation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "#Importing the NLTK toolkit along with Regular Expression\n",
    "import re \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize,PunktSentenceTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Opening of files like we did in TFIDF Algo design "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the same file format as we had used Previously for TFIDF algo design\n",
    "txt_f1 = open('someplain_test.txt','w')\n",
    "txt_f1.close()\n",
    "\n",
    "resume = open('resume.txt','r') #Reading the resume which will be parsed\n",
    "resume_lower = resume.read().lower() #for our convenience reading everything in lowercase letter\n",
    "\n",
    "#print(resume_lower)  \n",
    "headings_list = open('someplain_test.txt','a')  #opening the file in append mode\n",
    "\n",
    "#Defining the stopwords\n",
    "education_words = set(stopwords.words('english'))\n",
    "print(education_words)\n",
    "print(len(education_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading the resume and filtering it from any unwanted symbols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the resume\n",
    "text_resume = resume.readlines()\n",
    "words_resume = []\n",
    "\n",
    "headings_1 = []\n",
    "for i in text_resume:\n",
    "    words_resume = i.split()\n",
    "    if len(words_resume) <= 5 and i != '\\n' and i != ' ' and words_resume != '\\n' :\n",
    "        if i not in education_words:\n",
    "            headings_1.append(i)\n",
    "            final  = i.replace(('•'),(''))\n",
    "            #print(type(final))\n",
    "            final1 = final.replace((''),(''))\n",
    "            #print(type(final1))\n",
    "            ff  = final1.replace(('.'),(''))           #Elimination of some or certain type of symbols\n",
    "            ff1 = ff.replace((''),(''))\n",
    "            #print(type(ff),type(ff1))\n",
    "            headings_list.write(ff1.lower())\n",
    "            headings_list.write('\\n')\n",
    "#             sleep(2)\n",
    "            \n",
    "#Closing the document\n",
    "headings_list.close()\n",
    "print(type(headings_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation of stopwords present within the NLTK corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering on basis of stopwords  \n",
    "stop_words = set(stopwords.words(\"english\"))          #Stores some generalised stopwords present within the corpus\n",
    "\n",
    "with open('total.txt','r') as all_headings:\n",
    "        all_headings_list =[]\n",
    "        for heads in all_headings:\n",
    "                heads = heads.lower().strip()                                    #Stores all the headings Dataset\n",
    "                all_headings_list.append(heads)\n",
    "\n",
    "filterd_resume_text = open('someplain_test.txt','r')\n",
    "unfilterd_headings=filterd_resume_text.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the filtered values\n",
    "print(unfilterd_headings,filterd_resume_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing any new lines and horizontal tabs from the documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminating the nextlines and tabs present in the head text files \n",
    "\n",
    "head_list1 = []\n",
    "head_list2 = []\n",
    "print(all_headings_list)\n",
    "for word in unfilterd_headings:\n",
    "        print(word)\n",
    "        j = word.replace('\\n','')\n",
    "        #k= word.replace('\\t','')              #Eliminating any nextlines and tabs present in head text file\n",
    "        head_list1.append(j)\n",
    "for word in head_list1:\n",
    "        jj = word.replace('\\t','')\n",
    "        head_list2.append(jj)\n",
    "print(head_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edfile = open('edfile_detail.txt','w')\n",
    "tech_file = open('tech.txt','w')         #Storing important feature information of the document\n",
    "exp_file = open('exper.txt','w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtering words and comparing them with the train set and actual set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word filtering takes place\n",
    "\n",
    "head_list3=[]\n",
    "for words in head_list2:\n",
    "        print(words)\n",
    "        if words not in education_words and  stop_words and words!='':      #filtering the words\n",
    "                head_list3.append(words.strip())\n",
    "                \n",
    "print(head_list3)\n",
    "# sleep(2)\n",
    "# #print(head.split())\n",
    "finalheading1 = []\n",
    "for i in range(0,len(head_list3)):\n",
    "        for j in range(0,len(all_headings_list)):\n",
    "                r = nltk.edit_distance(head_list3[i], all_headings_list[j])      #comparing the train set headings and actual resume\n",
    "                if r < 2:\n",
    "                        #print(head_list3[i],all_headings_list[j],r)\n",
    "                        finalheading1.append(head_list3[i])\n",
    "                        #sleep(1)\n",
    "\n",
    "\n",
    "#Dispalying the results                        \n",
    "print(head_list3)\n",
    "print(finalheading1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining function named compute_information(). This method takes in two parameters one is the headings and the other is the custom value. It takes the key_words from the main function and tries to save the extracted data onto respective files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following function takes the key_words list from main function and saves extracted data onto respective files\n",
    "\n",
    "def compute_information(head,show):\n",
    "    for i in range(0,len(finalheading1)):  #running the loop till end of list\n",
    "        for j in range(0,len(head)):       #runs until it reaches the end of the corresponding list\n",
    "            r = nltk.edit_distance(finalheading1[i],head[j]) #Comparing the similarity b/w headings in resume and keywords\n",
    "            if (r < 2):\n",
    "                try:\n",
    "                    #Error Handling\n",
    "                    pattern = finalheading1[i]\n",
    "                    pat = finalheading1[i+1]\n",
    "                    print(pattern,pat)\n",
    "                    \n",
    "                    #show=1\n",
    "                    if show == 1:\n",
    "                        print(show)\n",
    "                        out = skills(pattern,pat)  #Calling the skills function\n",
    "                        out1 = ''.join(out)\n",
    "                        edfile.write(str(out1))\n",
    "                        \n",
    "                    if show  == 2:\n",
    "                        tec = skills(pattern,pat)\n",
    "                        tec1 = ''.join(tec)\n",
    "                        tech_file.write(str(tec1))\n",
    "                        \n",
    "                    if show == 3:\n",
    "                        ex = skills(pattern,pat)\n",
    "                        ex1 = ''.join(ex)\n",
    "                        exp_file = write(str(ex1))\n",
    "\n",
    "\n",
    "                except IndexError:                              #catch if any error present \n",
    "                    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main Function from where all the calling functionalities happen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking I/P from the users\n",
    "\n",
    "show = int(input(\"Enter \\n Education_skills: 1\\n Technical skills: 2\\n Experince       : 3 \\n Exit            : 0\\n\"))\n",
    "#print(show)\n",
    "\n",
    "#Running the loop till the input \"0\" is entered\n",
    "while show !=0:\n",
    "\n",
    "\n",
    "        if show == 1:                                #Education skills extraction \n",
    "                #Opens the file education keywords database file.\n",
    "                with open('education.txt','r') as education:\n",
    "                        Education = []                                  #Empty list to store the database\n",
    "                        for HEAD in education:\n",
    "                                HEAD = HEAD.lower().strip()             #extract each keyword from file and eliminates the space  \n",
    "                                Education.append(HEAD)                  #Adding to education list \n",
    "                #print(Education,show)                                  #Displaying the list with all the database \n",
    "                print(compute_information(Education,show))              #calls the function and prints the returned value\n",
    "\n",
    "                \n",
    "        if show == 2:\n",
    "                #Opens the file Technical skills key words database file.\n",
    "                with open('technical.txt','r') as technical:    \n",
    "                        Technical_skills = []\n",
    "                        for HEAD1 in technical:\n",
    "                                HEAD1 = HEAD1.lower().strip()\n",
    "                                Technical_skills.append(HEAD1)\n",
    "                #print(Technical_skills)\n",
    "                print(compute_information(Technical_skills,show))\n",
    "                #tech_file.close()\n",
    "        if show == 3:\n",
    "                #Opens the file Experience skills keywords database file.\n",
    "                with open('experience.txt','r') as experience:   \n",
    "                        Experience = []\n",
    "                        for HEAD2 in experience:\n",
    "                                HEAD2 = HEAD2.lower().strip()\n",
    "                                Experience.append(HEAD2)\n",
    "                #print(Experience)\n",
    "                print(Compute_Info(Experience,show))\n",
    "                #exp_file.close()\n",
    "        show = int(input(\"Enter \\n Education_skills: 1\\n Technical skills: 2\\n Experince       : 3 \\n Exit            : 0\\n\"))\n",
    "edfile_detail.close() \n",
    "tech_short.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
